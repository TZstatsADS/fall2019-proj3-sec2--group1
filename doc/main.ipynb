{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import import_ipynb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"R_USER\"] = \"Jiyoung Sim\" # user name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2 import robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects import numpy2ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 0: Provide directories for training images. Training images and Training fiducial points will be in different subfolders. \n",
    "train_dir = './data/train_set/' # This will be modified for different data sets.\n",
    "train_image_dir = train_dir + 'images/'\n",
    "train_pt_dir = train_dir + 'points/'\n",
    "train_label_path = train_dir + 'label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1: set up controls for evaluation experiments.\n",
    "run_feature_train = True # process features for training set\n",
    "run_train = True\n",
    "run_test = True # run evaluation on an independent test set\n",
    "run_feature_test = True # process features for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2: import data and train-test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "info = pd.read_csv(train_label_path)\n",
    "train_idx_py, test_idx_py = train_test_split(range(len(info)), test_size=0.2, random_state = 0)\n",
    "train_idx_r = [i+1 for i in train_idx_py]\n",
    "test_idx_r = [i+1 for i in test_idx_py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3: construct features and responses\n",
    "feature = robjects.r(\n",
    "    '''\n",
    "    source('./lib/feature.R')\n",
    "    '''\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = len(os.listdir(train_pt_dir))\n",
    "\n",
    "#function to read fiducial points\n",
    "#input: index\n",
    "#output: matrix of fiducial points corresponding to the index\n",
    "def readMat(index):\n",
    "    import scipy.io\n",
    "    numpy2ri.activate()\n",
    "    try:\n",
    "        mat = np.round(scipy.io.loadmat(train_pt_dir + '{:04n}.mat'.format(index))['faceCoordinatesUnwarped'])\n",
    "    except KeyError:\n",
    "        mat = np.round(scipy.io.loadmat(train_pt_dir + '{:04n}.mat'.format(index))['faceCoordinates2'])\n",
    "    nr,nc = mat.shape\n",
    "    mat_r = robjects.r.matrix(mat, nrow=nr, ncol=nc)\n",
    "    robjects.r.assign(\"mat\", mat_r)\n",
    "    return mat_r\n",
    "\n",
    "#load fiducial points\n",
    "fiducial_pt_list = [readMat(index) for index in range(1, n_files+1)]\n",
    "# save fiducial_pt_list.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "info_rdf = pandas2ri.py2ri(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    }
   ],
   "source": [
    "# %load_ext rpy2.ipython\n",
    "as_factor = robjects.r('''as.factor''')\n",
    "if(run_feature_train):\n",
    "    start = time.time()\n",
    "    dat_train_r = feature(fiducial_pt_list, train_idx_r, info_rdf)\n",
    "    end = time.time()\n",
    "    dat_train_py = pandas2ri.ri2py_dataframe(dat_train_r)\n",
    "    dat_train_r[-1] = as_factor(dat_train_r[-1])\n",
    "    tm_feature_train = end - start\n",
    "    dat_train_py.to_csv('dat_train_py.csv', index=False)\n",
    "\n",
    "if(run_feature_test):\n",
    "    start = time.time()\n",
    "    dat_test_r = feature(fiducial_pt_list, test_idx_r, info_rdf)\n",
    "    end = time.time()\n",
    "    dat_test_py = pandas2ri.ri2py_dataframe(dat_test_r)\n",
    "    dat_test_r[-1] = as_factor(dat_test_r[-1])\n",
    "    tm_feature_test = end - start\n",
    "    dat_test_py.to_csv('dat_test_py.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from test_baseline.ipynb\n"
     ]
    }
   ],
   "source": [
    "### Step 4: Train a classification model with training features and responses\n",
    "# train\n",
    "# cv done inside\n",
    "# Input: a data frame containing features and labels and a parameter list.\n",
    "# Output:a trained model\n",
    "baseline_dir = 'baseline_train.sav'\n",
    "if (run_train==True):\n",
    "    import train_baseline\n",
    "    baseline = train_baseline.gbm_fn(dat_train_py.iloc[:,:-1], dat_train_py.iloc[:,-1])\n",
    "    \n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(baseline, baseline_dir) # save the model to disk\n",
    "\n",
    "# test\n",
    "# Input: features and model directory \n",
    "# Output: training model specification\n",
    "if (run_test==True):\n",
    "    import test_baseline\n",
    "    baseline_acc = test_baseline.test_clf(dat_test_py, baseline_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = pd.concat([dat_train_py, dat_test_py]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_pca = robjects.r(\n",
    "#     '''\n",
    "#     source('./lib/feature_pca.R')\n",
    "#     '''\n",
    "# )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_thre_r = feature_pca(all_features, info_rdf)\n",
    "# pca_thre_py = pandas2ri.ri2py_dataframe(pca_thre)\n",
    "# pca_thre_r[-1] = as_factor(pca_thre_r[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarize Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from feature_cnn.ipynb\n",
      "Found 2000 validated image filenames belonging to 22 classes.\n",
      "Found 500 validated image filenames belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "import feature_cnn\n",
    "train_generator = feature_cnn.dat_generator(train_idx_py, True, train_image_dir, info)\n",
    "test_generator = feature_cnn.dat_generator(test_idx_py, False, train_image_dir, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
