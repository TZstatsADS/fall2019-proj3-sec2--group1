---
title: "XgBoost"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
require(dplyr)
require(ggplot2)
require(glue)
require(caret)
require(xgboost)
require(data.table)
require(vcd)
require(e1071)
require(ModelMetrics)
require(OpenMPController) # for Kaggle backend
require(readr)
require(vtreat)


set.seed(0)
omp_set_num_threads(4) # caret parallel processing threads

```

### Boolean
```{r}
run.pca<-FALSE
run.HOG<-TRUE
run.myfeature1<-FALSE

```

### 1. Using extractedpca
```{r}
if(run.pca){
# Load dataset in memory.

load("../output/extractedpca.RData")


# split the test, train dataset
train_idx <- sample(1:2500, 2000)
train_xgb <- data.frame(pca_thre)[train_idx,]

test_idx <- setdiff(1:2500, train_idx)
test_xgb<- data.frame(pca_thre)[test_idx,]


# rename the label column
names(train_xgb)[31] <- "label"
names(test_xgb)[31] <- "label"
# factorize label column
train_xgb$label <- factor(train_xgb$label)
test_xgb$label <- factor(test_xgb$label)


# Here we use 10-fold cross-validation, repeating twice, and using random search for tuning hyper-parameters.
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 2, search = "random", allowParallel = TRUE)

# train a xgbTree model using caret::train
train_xgb_dat<-train_xgb[,1:30]


xgb_model <- caret::train(
  x = train_xgb_dat,
  y = train_xgb$label,
  trControl = fitControl,
  method = "xgbLinear",
  verbose = TRUE
)

print(xgb_model) # Model results



# Prediction
y_pred_xgb <- predict(xgb_model, test_xgb)


# calculate accuracy
accu_xgb <- mean(test_xgb$label == y_pred_xgb)
cat("The accuracy of model on selected feature:", "is", accu_xgb*100, "%.\n")

caret::confusionMatrix(y_pred_xgb, test_xgb$label)
}
```


## 2. Using HOG
### Load the data and split test train dataset
```{r}
if(run.HOG){
load("../output/HOG.RData")
# split the test, train dataset
train_hog <- data.frame(dat)[train_idx,]
test_hog<- data.frame(dat)[test_idx,]

# rename the label column
names(train_hog)[55] <- "label"
names(test_hog)[55] <- "label"

# factorize label column
train_hog$label <- factor(train_hog$label)
test_hog$label <- factor(test_hog$label)

# Set up control parameters for caret::train
# Here we use 10-fold cross-validation, repeating twice, and using random search for tuning hyper-parameters.
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 2, search = "random", allowParallel = TRUE)

# train a xgbTree model using caret::train
train_hog_dat<-train_hog[,1:30]


hog_model <- caret::train(
  x = train_hog_dat,
  y = train_hog$label,
  trControl = fitControl,
  method = "xgbLinear",
  verbose = TRUE
)


print(hog_model) # Model results

# Prediction
y_pred_hog <- predict(hog_model, test_hog)


# calculate accuracy
accu_hog <- mean(test_hog$label == y_pred_hog)
cat("The accuracy of model on selected feature:", "is", accu_hog*100, "%.\n")

caret::confusionMatrix(y_pred_hog, test_hog$label)
}
```

## 3. Using myfeature1
### Load the data and split test train dataset

```{r}
if(run.myfeature1){
load("../output/myfeature1.RData")
# split the test, train dataset
train_f1 <- data.frame(mydat)[train_idx,]
test_f1<- data.frame(mydat)[test_idx,]

# rename the label column
names(train_f1)[507] <- "label"
names(test_f1)[507] <- "label"

# factorize label column
train_f1$label <- factor(train_f1$label)
test_f1$label <- factor(test_f1$label)


# Set up control parameters for caret::train
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 2, search = "random", allowParallel = TRUE)

# train a xgbTree model using caret::train
train_f1_dat<-train_f1[,1:30]

f1_model <- caret::train(
  x = train_f1_dat,
  y = train_f1$label,
  trControl = fitControl,
  method = "xgbLinear",
  verbose = TRUE
)

print(f1_model) # Model results

# Prediction
y_pred_f1 <- predict(f1_model, test_f1)


# calculate accuracy
accu_f1<- mean(test_f1$label == y_pred_f1)
cat("The accuracy of model on selected feature:", "is", accu_f1*100, "%.\n")

caret::confusionMatrix(y_pred_f1, test_f1$label)
}
```


